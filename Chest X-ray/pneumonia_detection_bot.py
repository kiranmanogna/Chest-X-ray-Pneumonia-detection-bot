# -*- coding: utf-8 -*-
"""Pneumonia_detection_bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R7YAYTm_X_KiCIm08DrzEIEz4L3psn34
"""

!pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia", force=True)

!pip install pyTelegramBotAPI requests
!pip install openai


import telebot
import requests
from PIL import Image
import io
import io
import openai
#from transformers import AutoModelForImageClassification, ViTImageProcessor
from io import BytesIO
#import multiprocessing
#from builtins import input
from multiprocessing import Process

!pip install -q transformers
from transformers import ViTImageProcessor,AutoModelForImageClassification
processor=ViTImageProcessor.from_pretrained("nickmuchi/vit-base-xray-pneumonia")
model=AutoModelForImageClassification.from_pretrained("nickmuchi/vit-base-xray-pneumonia")

bot_token = '6228349095:AAFIqa1uHLXpHNpNe6Bi19zpUvbVhE8Y3dI'
bot = telebot.TeleBot(bot_token)

openai.api_key = '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'
import torch
device=torch.device("cuda" if torch.cuda.is_available() else "cpu")
from torchvision.transforms import functional as F

@bot.message_handler(commands=['start'])
def handle_start(message):
    #print a message in the console
    bot.send_message(message.chat.id, "welcome to the pneumonia detection bot")


@bot.message_handler(content_types=['photo'])
def handle_message(message):
    #get the image file Id
    file_id = message.photo[-1].file_id

    #get the image file
    file_info = bot.get_file(file_id)
    file_bytes = bot.download_file(file_info.file_path)
    class_probs = process_image(file_bytes )
    print(class_probs)

    #process the image
    pneumonia_prob = class_probs.get('PNEUMONIA',0)
    if pneumonia_prob > 0.4:
        reply_text = "<b> Pneumonia detected!</b>"
    else:
        reply_text = "<b> No pneumonia detected.</b>"

    #send the reply
    bot.reply_to(message, reply_text, parse_mode='HTML')
    reply_text = "Class probabilities:\n"
    for class_label,prob in class_probs.items():
        reply_text += f"{class_label}: {prob*100}\n"

    bot.reply_to(message, reply_text)

def process_image(image_bytes):
    #preprocess the input image
    image = Image.open(BytesIO(image_bytes))
    image = image.convert("RGB")
   # image = image.resize( )
    inputs =processor(image, return_tensors="pt")
    inputs = inputs.to(device)

    #perform inference
    outputs = model(**inputs)

    #get predocted probabilities
    probs = torch.softmax(outputs.logits, dim=1)
    probs = probs.detach().cpu().numpy().squeeze()

    #get class labels
    labels = model.config.id2label
    class_probs = {labels[i]: probs[i] for i in range(len(probs))}
    return class_probs

bot.polling()